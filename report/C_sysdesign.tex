\section{System Design}
\label{chap:sysdesign}
%System Design (recommended size: 1.5 pages)
Here is where ambition and reality start to diverge. This section proposes an implementation of DAS using Trailing State Servers (TSSs). However, we did not accomplish to implement this proposal.

\subsection{System Overview}
%describe the design of your system, including the system operation, fault tolerance, and scalability components (which correspond to the homonym features required by the WantGame CTO).
We wanted to implement the distributed aspect of the DAS-game using TSSs. The idea behind TSSs is that each server contain not only the state of the game, but also several trailing states. These trailing states contain the state of the game with a (small) delay. This means that all moves are timestamped when they arrive at the first server. The delay of executing the move is then based on that timestamp.\\
A bigger delay on the trailing server means that it can catch more out of order moves and execute them in the right order anyway. Then we can compare the effects the move had in the different trailing states. If the effects are different in a trailing state with a bigger delay, we know 2 things:\\
1. The more recent trailing state executed moves out-of-order. We know this because the only difference in the trailing states with a bigger delay is that it re-orders moves that it hasn't executed yet, which arrived in the wrong order. \\
2. Executing the moves in the wrong order had an impact on the game. Since the move actually had a different effect in the trailing state with a larger delay, we know executing the move out-of-order impacted the game.\\
This is especially helpful in the DAS-game since most moves in that game can be performed out of order. For example, a move that just does damage but doesn't kill anything can be performed out-of-order with just about any other move and the result will be the same. Also a step of a player can only conflict with: another move of that player, an heal or attack on that player and another player moving to the square this player is moving to.\\
This is so much the case that in our first try, we modified the TSSs concept to make use of this. In this version the trailing states only compared a move that came in with the moves that haven't executed yet, but need to be executed earlier. We noted a conflict when (after comparing the new move with the earlier moves one by one) whether a conflict could arise.\\
This version was highly dependent on the function that signals whether 2 moves can create a different state when they are executed in swapped order. This function was very difficult to write and it was very difficult to ensure that all edge-cases are covered. So we abandoned this concept, however, this would be a optimization of TSSs to be considered for even simpler games.\\
After this optimization was discarded, the focus shifted to implementing regular TSSs. Using this concept the design would consist of servers and clients. The server would be running a server (java-)object that contains several trailing state objects. Each trailing state would contain a Battlefield object, which contains the state of the game.\\
The client would send a move(-object) using Java RMI to 2 servers. The client would also send to both servers the id of the other server it sent its move to. Those servers timestamp the move, exchange it and the server which timestamped the move with the earliest time, distributes the move to all servers with that time.If the timestamps are the same, the server with the lowest server-id distributes the move. If a server crashes, all servers are informed about which server crashed. If a server is still waiting to exchange a move with the crashed server, it stop waiting and starts sending the move to all other servers anyway. This way in a single server crash, no moves are lost. This is an important part of our fault tolerance requirement. \\
Note that we might want to allow for multiple server crashes. In the case of allowing for n server crashes at a time, we need to send each move to n+1 servers. Those servers then perform a leader selection algorithm to find the server with the earliest timestamp. Again: each server is told which other servers have received the move and when 2 servers have the same earliest timestamp, the server with the smallest server-id distributes the move. \\
When a server receives a move from another server, it inserts the move in each of its trailing states. Each time the move is executed in a trailing state, its effect is compared to the effect of the same move in the first trailing state with a shorter delay. That comparison is made easy by storing the effects of a move in an array of MoveEffect-objects in the Move object itself. When the effects of the move aren't the same as the effects in the first trailing state with less delay, a roll-back is called.\\
A roll-back consists of taking the Battlefield of the trailing state with the next higher delay as well as the list of moves that state still needs to execute. Then, execute any moves you can already execute with your lower delay. After updating our own state, the roll-back function is called of the next more recent state. This way the roll-back propagates to the most recent state, while preventing any double work. \\
Clients now get the state of the game sent to them by their closest server each 50 ms (the time needed to create a 'twitch' feel to the game). This state is a compressed version of the Battlefield-object of the trailing state with the smallest delay on the server the client is requesting. The compacted battlefield only consists of a list of units, their locations and their healths, where each unit is either marked as 'player', 'dragon' or 'client' for the unit the client controls. This can then be displayed by the battlefield-viewer running on the clients computer.\\
This allows each client to have a real-time view on a best effort display of the state of the game. While at the same time each move is processed in order eventually (under the assumption that the largest delay of the trailing states is larger than the delay in the server network). This fulfils our first requirement that the game runs as specified by WantGame BV. Also the use of multiple servers, any of which the clients can connect to make this set-up scalable, our third requirement.\\
Lastly we need to deal with clients who crash or are otherwise ungracefully disconnected. We deal with this by requiring clients to contact their server at least every few hundred ms even if no commands were issued in that time. The clients themselves choose how long they wish to remain in the game when their connection (temporarily) drops. Clients with an unreliable connection might for example choose to only be removed from the game when the connection is lost for 10 seconds. On the other hand, high-level players might ask to be dropped if their connection fails for only 100 ms. This way, they are assured their connection is good as long as they remain in the game playing. \\
We base the maximum time between two messages from the client to the server on this 'disconnection time'. The clients has to send at least ten messages to the server in the 'disconnection window'. This means that if a player wants to be disconnected after 100 ms, the client has to send a command or a ping to the server each 10 ms. If a player wants to remain in the game until 10 s after the last received message from him/her, the client only has to send a command/ping every second. This means that for a functioning client to be dropped, at least 10 packets from the client to the sever must have been lost in the connection. \\
Lastly as a sanity condition, we enforce that the 'disconnection window' must be between 50 ms and 20 s. This also means that the game will end at most 20 seconds after the last message from a client is received. This means that clients can crash without interrupting the game-play of other players. This is part of our fault-tolerance requirement.